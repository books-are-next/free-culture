---
title: Afterword
---
**At least some** who have read this far will agree with me that something must be done to change where we are heading.
The balance of this book maps what might be done.

I divide this map into two parts: that which anyone can do now, and that which requires the help of lawmakers.
If there is one lesson that we can draw from the history of remaking common sense, it is that it requires remaking how many people think about the very same issue.

That means this movement must begin in the streets.
It must recruit a significant number of parents, teachers, librarians, creators, authors, musicians, filmmakers, scientists—all to tell this story in their own words, and to tell their neighbors why this battle is so important.

Once this movement has its effect in the streets, it has some hope of having an effect in Washington.
We are still a democracy.
What people think matters.
Not as much as it should, at least when an RCA stands opposed, but still, it matters.
And thus, in the second part below, I sketch changes that Congress could make to better secure a free culture.

***

## US, NOW

**Common sense** is with the copyright warriors because the debate so far has been framed at the extremes—as a grand either/or: either property or anarchy, either total control or artists won't be paid.
If that really is the choice, then the warriors should win.

The mistake here is the error of the excluded middle.
There are extremes in this debate, but the extremes are not all that there is. There are those who believe in maximal copyright—“All Rights Reserved”—and those who reject copyright—“No Rights Reserved.”
The “All Rights Reserved” sorts believe that you should ask permission before you “use” a copyrighted work in any way.
The “No Rights Reserved” sorts believe you should be able to do with content as you wish, regardless of whether you have permission or not.

When the Internet was first born, its initial architecture effectively tilted in the “no rights reserved” direction.
Content could be copied perfectly and cheaply; rights could not easily be controlled.
Thus, regardless of anyone's desire, the effective regime of copyright under the original design of the Internet was “no rights reserved.”
Content was “taken” regardless of the rights.
Any rights were effectively unprotected.

This initial character produced a reaction (opposite, but not quite equal) by copyright owners.
That reaction has been the topic of this book.
Through legislation, litigation, and changes to the network's design, copyright holders have been able to change the essential character of the environment of the original Internet.
If the original architecture made the effective default “no rights reserved,” the future architecture will make the effective default “all rights reserved.”
The architecture and law that surround the Internet's design will increasingly produce an environment where all use of content requires permission.
The “cut and paste” world that defines the Internet today will become a “get permission to cut and paste” world that is a creator's nightmare.

What's needed is a way to say something in the middle—neither “all rights reserved” nor “no rights reserved” but “some rights reserved”—and thus a way to respect copyrights but enable creators to free content as they see fit.
In other words, we need a way to restore a set of freedoms that we could just take for granted before.

### Rebuilding Freedoms Previously

Presumed: Examples

If you step back from the battle I've been describing here, you will recognize this problem from other contexts.
Think about privacy.
Before the Internet, most of us didn't have to worry much about data about our lives that we broadcast to the world.
If you walked into a bookstore and browsed through some of the works of Karl Marx, you didn't need to worry about explaining your browsing habits to your neighbors or boss.
The “privacy” of your browsing habits was assured.

What made it assured?

Well, if we think in terms of the modalities I described in chapter 10, your privacy was assured because of an inefficient architecture for gathering data and hence a market constraint (cost) on anyone who wanted to gather that data.
If you were a suspected spy for North Korea, working for the CIA, no doubt your privacy would not be assured.
But that's because the CIA would (we hope) find it valuable enough to spend the thousands required to track you.
But for most of us (again, we can hope), spying doesn't pay.
The highly inefficient architecture of real space means we all enjoy a fairly robust amount of privacy.
That privacy is guaranteed to us by friction.
Not by law (there is no law protecting “privacy” in public places), and in many places, not by norms (snooping and gossip are just fun), but instead, by the costs that friction imposes on anyone who would want to spy.

Enter the Internet, where the cost of tracking browsing in particular has become quite tiny.
If you're a customer at Amazon, then as you browse the pages, Amazon collects the data about what you've looked at. You know this because at the side of the page, there's a list of “recently viewed” pages.
Now, because of the architecture of the Net and the function of cookies on the Net, it is easier to collect the data than not.
The friction has disappeared, and hence any “privacy” protected by the friction disappears, too.

Amazon, of course, is not the problem.
But we might begin to worry about libraries.
If you're one of those crazy lefties who thinks that people should have the “right” to browse in a library without the government knowing which books you look at (I'm one of those lefties, too), then this change in the technology of monitoring might concern you.
If it becomes simple to gather and sort who does what in electronic spaces, then the friction-induced privacy of yesterday disappears.

It is this reality that explains the push of many to define “privacy” on the Internet.
It is the recognition that technology can remove what friction before gave us that leads many to push for laws to do what friction did.[^210]
And whether you're in favor of those laws or not, it is the pattern that is important here.
We must take affirmative steps to secure a kind of freedom that was passively provided before.
A change in technology now forces those who believe in privacy to affirmatively act where, before, privacy was given by default.

A similar story could be told about the birth of the free software movement.
When computers with software were first made available commercially, the software—both the source code and the binaries—was free.
You couldn't run a program written for a Data General machine on an IBM machine, so Data General and IBM didn't care much about controlling their software.

That was the world Richard Stallman was born into, and while he was a researcher at MIT, he grew to love the community that developed when one was free to explore and tinker with the software that ran on machines.
Being a smart sort himself, and a talented programmer, Stallman grew to depend upon the freedom to add to or modify other people's work.

In an academic setting, at least, that's not a terribly radical idea.
In a math department, anyone would be free to tinker with a proof that someone offered.
If you thought you had a better way to prove a theorem, you could take what someone else did and change it. In a classics department, if you believed a colleague's translation of a recently discovered text was flawed, you were free to improve it. Thus, to Stallman, it seemed obvious that you should be free to tinker with and improve the code that ran a machine.
This, too, was knowledge.
Why shouldn't it be open for criticism like anything else?

No one answered that question.
Instead, the architecture of revenue for computing changed.
As it became possible to import programs from one system to another, it became economically attractive (at least in the view of some) to hide the code of your program.
So, too, as companies started selling peripherals for mainframe systems.
If I could just take your printer driver and copy it, then that would make it easier for me to sell a printer to the market than it was for you.

Thus, the practice of proprietary code began to spread, and by the early 1980s, Stallman found himself surrounded by proprietary code.
The world of free software had been erased by a change in the economics of computing.
And as he believed, if he did nothing about it, then the freedom to change and share software would be fundamentally weakened.

Therefore, in 1984, Stallman began a project to build a free operating system, so that at least a strain of free software would survive.
That was the birth of the GNU project, into which Linus Torvalds's “Linux” kernel was added to produce the GNU/Linux operating system.

Stallman's technique was to use copyright law to build a world of software that must be kept free.
Software licensed under the Free Software Foundation's GPL cannot be modified and distributed unless the source code for that software is made available as well.
Thus, anyone building upon GPL'd software would have to make their buildings free as well.
This would assure, Stallman believed, that an ecology of code would develop that remained free for others to build upon.
His fundamental goal was freedom; innovative creative code was a byproduct.

Stallman was thus doing for software what privacy advocates now do for privacy.
He was seeking a way to rebuild a kind of freedom that was taken for granted before.
Through the affirmative use of licenses that bind copyrighted code, Stallman was affirmatively reclaiming a space where free software would survive.
He was actively protecting what before had been passively guaranteed.

Finally, consider a very recent example that more directly resonates with the story of this book.
This is the shift in the way academic and scientific journals are produced.

As digital technologies develop, it is becoming obvious to many that printing thousands of copies of journals every month and sending them to libraries is perhaps not the most efficient way to distribute knowledge.
Instead, journals are increasingly becoming electronic, and libraries and their users are given access to these electronic journals through password-protected sites.
Something similar to this has been happening in law for almost thirty years: Lexis and Westlaw have had electronic versions of case reports available to subscribers to their service.
Although a Supreme Court opinion is not copyrighted, and anyone is free to go to a library and read it, Lexis and Westlaw are also free to charge users for the privilege of gaining access to that Supreme Court opinion through their respective services.

There's nothing wrong in general with this, and indeed, the ability to charge for access to even public domain materials is a good incentive for people to develop new and innovative ways to spread knowledge.
The law has agreed, which is why Lexis and Westlaw have been allowed to flourish.
And if there's nothing wrong with selling the public domain, then there could be nothing wrong, in principle, with selling access to material that is not in the public domain.

But what if the only way to get access to social and scientific data was through proprietary services?
What if no one had the ability to browse this data except by paying for a subscription?

As many are beginning to notice, this is increasingly the reality with scientific journals.
When these journals were distributed in paper form, libraries could make the journals available to anyone who had access to the library.
Thus, patients with cancer could become cancer experts because the library gave them access.
Or patients trying to understand the risks of a certain treatment could research those risks by reading all available articles about that treatment.
This freedom was therefore a function of the institution of libraries (norms) and the technology of paper journals (architecture)—namely, that it was very hard to control access to a paper journal.

As journals become electronic, however, the publishers are demanding that libraries not give the general public access to the journals.
This means that the freedoms provided by print journals in public libraries begin to disappear.
Thus, as with privacy and with software, a changing technology and market shrink a freedom taken for granted before.

This shrinking freedom has led many to take affirmative steps to restore the freedom that has been lost.
The Public Library of Science (PLoS), for example, is a nonprofit corporation dedicated to making scientific research available to anyone with a Web connection.
Authors of scientific work submit that work to the Public Library of Science.
That work is then subject to peer review.
If accepted, the work is then deposited in a public, electronic archive and made permanently available for free.
PLoS also sells a print version of its work, but the copyright for the print journal does not inhibit the right of anyone to redistribute the work for free.

This is one of many such efforts to restore a freedom taken for granted before, but now threatened by changing technology and markets.
There's no doubt that this alternative competes with the traditional publishers and their efforts to make money from the exclusive distribution of content.
But competition in our tradition is presumptively a good—especially when it helps spread knowledge and science.

### Rebuilding Free Culture: One Idea

The same strategy could be applied to culture, as a response to the increasing control effected through law and technology.

Enter the Creative Commons.
The Creative Commons is a nonprofit corporation established in Massachusetts, but with its home at Stanford University.
Its aim is to build a layer of _reasonable_ copyright on top of the extremes that now reign.
It does this by making it easy for people to build upon other people's work, by making it simple for creators to express the freedom for others to take and build upon their work.
Simple tags, tied to human-readable descriptions, tied to bullet-proof licenses, make this possible.

_Simple_—which means without a middleman, or without a lawyer.
By developing a free set of licenses that people can attach to their content, Creative Commons aims to mark a range of content that can easily, and reliably, be built upon.
These tags are then linked to machine-readable versions of the license that enable computers automatically to identify content that can easily be shared.
These three expressions together—a legal license, a human-readable description, and machine-readable tags—constitute a Creative Commons license.
A Creative Commons license constitutes a grant of freedom to anyone who accesses the license, and more importantly, an expression of the ideal that the person associated with the license believes in something different than the “All” or “No” extremes.
Content is marked with the CC mark, which does not mean that copyright is waived, but that certain freedoms are given.

These freedoms are beyond the freedoms promised by fair use.
Their precise contours depend upon the choices the creator makes.
The creator can choose a license that permits any use, so long as attribution is given.
She can choose a license that permits only noncommercial use.
She can choose a license that permits any use so long as the same freedoms are given to other uses (“share and share alike”). Or any use so long as no derivative use is made.
Or any use at all within developing nations.
Or any sampling use, so long as full copies are not made.
Or lastly, any educational use.

These choices thus establish a range of freedoms beyond the default of copyright law.
They also enable freedoms that go beyond traditional fair use.
And most importantly, they express these freedoms in a way that subsequent users can use and rely upon without the need to hire a lawyer.
Creative Commons thus aims to build a layer of content, governed by a layer of reasonable copyright law, that others can build upon.
Voluntary choice of individuals and creators will make this content available.
And that content will in turn enable us to rebuild a public domain.

This is just one project among many within the Creative Commons.
And of course, Creative Commons is not the only organization pursuing such freedoms.
But the point that distinguishes the Creative Commons from many is that we are not interested only in talking about a public domain or in getting legislators to help build a public domain.
Our aim is to build a movement of consumers and producers of content (“content conducers,” as attorney Mia Garlick calls them) who help build the public domain and, by their work, demonstrate the importance of the public domain to other creativity.

The aim is not to fight the “All Rights Reserved” sorts.
The aim is to complement them.
The problems that the law creates for us as a culture are produced by insane and unintended consequences of laws written centuries ago, applied to a technology that only Jefferson could have imagined.
The rules may well have made sense against a background of technologies from centuries ago, but they do not make sense against the background of digital technologies.
New rules—with different freedoms, expressed in ways so that humans without lawyers can use them—are needed.
Creative Commons gives people a way effectively to begin to build those rules.

Why would creators participate in giving up total control?
Some participate to better spread their content.
Cory Doctorow, for example, is a science fiction author.
His first novel, _Down and Out in the Magic Kingdom_, was released on-line and for free, under a Creative Commons license, on the same day that it went on sale in bookstores.

Why would a publisher ever agree to this?
I suspect his publisher reasoned like this: There are two groups of people out there: (1) those who will buy Cory's book whether or not it's on the Internet, and (2) those who may never hear of Cory's book, if it isn't made available for free on the Internet.
Some part of (1) will download Cory's book instead of buying it. Call them bad-(1)s. Some part of (2) will download Cory's book, like it, and then decide to buy it. Call them (2)-goods.
If there are more (2)-goods than bad-(1)s, the strategy of releasing Cory's book free on-line will probably _increase_ sales of Cory's book.

Indeed, the experience of his publisher clearly supports that conclusion.
The book's first printing was exhausted months before the publisher had expected.
This first novel of a science fiction author was a total success.

The idea that free content might increase the value of nonfree content was confirmed by the experience of another author.
Peter Wayner, who wrote a book about the free software movement titled _Free for All_, made an electronic version of his book free on-line under a Creative Commons license after the book went out of print.
He then monitored used book store prices for the book.
As predicted, as the number of downloads increased, the used book price for his book increased, as well.

These are examples of using the Commons to better spread proprietary content.
I believe that is a wonderful and common use of the Commons.
There are others who use Creative Commons licenses for other reasons.
Many who use the “sampling license” do so because anything else would be hypocritical.
The sampling license says that others are free, for commercial or noncommercial purposes, to sample content from the licensed work; they are just not free to make full copies of the licensed work available to others.
This is consistent with their own art—they, too, sample from others.
Because the _legal_ costs of sampling are so high (Walter Leaphart, manager of the rap group Public Enemy, which was born sampling the music of others, has stated that he does not “allow” Public Enemy to sample anymore, because the legal costs are so high[^211]), these artists release into the creative environment content that others can build upon, so that their form of creativity might grow.

Finally, there are many who mark their content with a Creative Commons license just because they want to express to others the importance of balance in this debate.
If you just go along with the system as it is, you are effectively saying you believe in the “All Rights Reserved” model.
Good for you, but many do not.
Many believe that however appropriate that rule is for Hollywood and freaks, it is not an appropriate description of how most creators view the rights associated with their content.
The Creative Commons license expresses this notion of “Some Rights Reserved,” and gives many the chance to say it to others.

In the first six months of the Creative Commons experiment, over 1 million objects were licensed with these free-culture licenses.
The next step is partnerships with middleware content providers to help them build into their technologies simple ways for users to mark their content with Creative Commons freedoms.
Then the next step is to watch and celebrate creators who build content based upon content set free.

These are first steps to rebuilding a public domain.
They are not mere arguments; they are action.
Building a public domain is the first step to showing people how important that domain is to creativity and innovation.
Creative Commons relies upon voluntary steps to achieve this rebuilding.
They will lead to a world in which more than voluntary steps are possible.

Creative Commons is just one example of voluntary efforts by individuals and creators to change the mix of rights that now govern the creative field.
The project does not compete with copyright; it complements it. Its aim is not to defeat the rights of authors, but to make it easier for authors and creators to exercise their rights more flexibly and cheaply.
That difference, we believe, will enable creativity to spread more easily.

***

THEM, SOON

**We will** not reclaim a free culture by individual action alone.
It will also take important reforms of laws.
We have a long way to go before the politicians will listen to these ideas and implement these reforms.
But that also means that we have time to build awareness around the changes that we need.

In this chapter, I outline five kinds of changes: four that are general, and one that's specific to the most heated battle of the day, music.
Each is a step, not an end.
But any of these steps would carry us a long way to our end.

### 1\. More Formalities

If you buy a house, you have to record the sale in a deed.
If you buy land upon which to build a house, you have to record the purchase in a deed.
If you buy a car, you get a bill of sale and register the car.
If you buy an airplane ticket, it has your name on it.

These are all formalities associated with property.
They are requirements that we all must bear if we want our property to be protected.

In contrast, under current copyright law, you automatically get a copyright, regardless of whether you comply with any formality.
You don't have to register.
You don't even have to mark your content.
The default is control, and “formalities” are banished.

Why?

As I suggested in chapter 10, the motivation to abolish formalities was a good one.
In the world before digital technologies, formalities imposed a burden on copyright holders without much benefit.
Thus, it was progress when the law relaxed the formal requirements that a copyright owner must bear to protect and secure his work.
Those formalities were getting in the way.

But the Internet changes all this.
Formalities today need not be a burden.
Rather, the world without formalities is the world that burdens creativity.
Today, there is no simple way to know who owns what, or with whom one must deal in order to use or build upon the creative work of others.
There are no records, there is no system to trace—there is no simple way to know how to get permission.
Yet given the massive increase in the scope of copyright's rule, getting permission is a necessary step for any work that builds upon our past.
And thus, the _lack_ of formalities forces many into silence where they otherwise could speak.

The law should therefore change this requirement[^212]—but it should not change it by going back to the old, broken system.
We should require formalities, but we should establish a system that will create the incentives to minimize the burden of these formalities.

The important formalities are three: marking copyrighted work, registering copyrights, and renewing the claim to copyright.
Traditionally, the first of these three was something the copyright owner did; the second two were something the government did.
But a revised system of formalities would banish the government from the process, except for the sole purpose of approving standards developed by others.

****REGISTRATION AND RENEWAL****

Under the old system, a copyright owner had to file a registration with the Copyright Office to register or renew a copyright.
When filing that registration, the copyright owner paid a fee.
As with most government agencies, the Copyright Office had little incentive to minimize the burden of registration; it also had little incentive to minimize the fee.
And as the Copyright Office is not a main target of government policy-making, the office has historically been terribly underfunded.
Thus, when people who know something about the process hear this idea about formalities, their first reaction is panic—nothing could be worse than forcing people to deal with the mess that is the Copyright Office.

Yet it is always astonishing to me that we, who come from a tradition of extraordinary innovation in governmental design, can no longer think innovatively about how governmental functions can be designed.
Just because there is a public purpose to a government role, it doesn't follow that the government must actually administer the role.
Instead, we should be creating incentives for private parties to serve the public, subject to standards that the government sets.

In the context of registration, one obvious model is the Internet.
There are at least 32 million Web sites registered around the world.
Domain name owners for these Web sites have to pay a fee to keep their registration alive.
In the main top-level domains (.com, .org, .net), there is a central registry.
The actual registrations are, however, performed by many competing registrars.
That competition drives the cost of registering down, and more importantly, it drives the ease with which registration occurs up.

We should adopt a similar model for the registration and renewal of copyrights.
The Copyright Office may well serve as the central registry, but it should not be in the registrar business.
Instead, it should establish a database, and a set of standards for registrars.
It should approve registrars that meet its standards.
Those registrars would then compete with one another to deliver the cheapest and simplest systems for registering and renewing copyrights.
That competition would substantially lower the burden of this formality—while producing a database of registrations that would facilitate the licensing of content.

### MARKING

It used to be that the failure to include a copyright notice on a creative work meant that the copyright was forfeited.
That was a harsh punishment for failing to comply with a regulatory rule—akin to imposing the death penalty for a parking ticket in the world of creative rights.
Here again, there is no reason that a marking requirement needs to be enforced in this way.
And more importantly, there is no reason a marking requirement needs to be enforced uniformly across all media.

The aim of marking is to signal to the public that this work is copyrighted and that the author wants to enforce his rights.
The mark also makes it easy to locate a copyright owner to secure permission to use the work.

One of the problems the copyright system confronted early on was that different copyrighted works had to be differently marked.
It wasn't clear how or where a statue was to be marked, or a record, or a film.
A new marking requirement could solve these problems by recognizing the differences in media, and by allowing the system of marking to evolve as technologies enable it to. The system could enable a special signal from the failure to mark—not the loss of the copyright, but the loss of the right to punish someone for failing to get permission first.

Let's start with the last point.
If a copyright owner allows his work to be published without a copyright notice, the consequence of that failure need not be that the copyright is lost.
The consequence could instead be that anyone has the right to use this work, until the copyright owner complains and demonstrates that it is his work and he doesn't give permission.[^213]
The meaning of an unmarked work would therefore be “use unless someone complains.”
If someone does complain, then the obligation would be to stop using the work in any new work from then on though no penalty would attach for existing uses.
This would create a strong incentive for copyright owners to mark their work.

That in turn raises the question about how work should best be marked.
Here again, the system needs to adjust as the technologies evolve.
The best way to ensure that the system evolves is to limit the Copyright Office's role to that of approving standards for marking content that have been crafted elsewhere.

For example, if a recording industry association devises a method for marking CDs, it would propose that to the Copyright Office.
The Copyright Office would hold a hearing, at which other proposals could be made.
The Copyright Office would then select the proposal that it judged preferable, and it would base that choice _solely_ upon the consideration of which method could best be integrated into the registration and renewal system.
We would not count on the government to innovate; but we would count on the government to keep the product of innovation in line with its other important functions.

Finally, marking content clearly would simplify registration requirements.
If photographs were marked by author and year, there would be little reason not to allow a photographer to reregister, for example, all photographs taken in a particular year in one quick step.
The aim of the formality is not to burden the creator; the system itself should be kept as simple as possible.

The objective of formalities is to make things clear.
The existing system does nothing to make things clear.
Indeed, it seems designed to make things unclear.

If formalities such as registration were reinstated, one of the most difficult aspects of relying upon the public domain would be removed.
It would be simple to identify what content is presumptively free; it would be simple to identify who controls the rights for a particular kind of content; it would be simple to assert those rights, and to renew that assertion at the appropriate time.

****2. Shorter Terms****

The term of copyright has gone from fourteen years to ninety-five years for corporate authors, and life of the author plus seventy years for natural authors.

In _The Future of Ideas_, I proposed a seventy-five-year term, granted in five-year increments with a requirement of renewal every five years.
That seemed radical enough at the time.
But after we lost _Eldred_ v. _Ashcroft_, the proposals became even more radical. _The Economist_ endorsed a proposal for a fourteen-year copyright term.[^214]
Others have proposed tying the term to the term for patents.

I agree with those who believe that we need a radical change in copyright's term.
But whether fourteen years or seventy-five, there are four principles that are important to keep in mind about copyright terms.

(1) _Keep it short:_ The term should be as long as necessary to give incentives to create, but no longer.
If it were tied to very strong protections for authors (so authors were able to reclaim rights from publishers), rights to the same work (not derivative works) might be extended further.
The key is not to tie the work up with legal regulations when it no longer benefits an author.

(2) _Keep it simple:_ The line between the public domain and protected content must be kept clear.
Lawyers like the fuzziness of “fair use,” and the distinction between “ideas” and “expression.”
That kind of law gives them lots of work.
But our framers had a simpler idea in mind: protected versus unprotected.
The value of short terms is that there is little need to build exceptions into copyright when the term itself is kept short.
A clear and active “lawyer-free zone” makes the complexities of “fair use” and “idea/expression” less necessary to navigate.

(3) _Keep it alive:_ Copyright should have to be renewed.
Especially if the maximum term is long, the copyright owner should be required to signal periodically that he wants the protection continued.
This need not be an onerous burden, but there is no reason this monopoly protection has to be granted for free.
On average, it takes ninety minutes for a veteran to apply for a pension.[^215]
If we make veterans suffer that burden, I don't see why we couldn't require authors to spend ten minutes every fifty years to file a single form.

(4) _Keep it prospective:_ Whatever the term of copyright should be, the clearest lesson that economists teach is that a term once given should not be extended.
It might have been a mistake in 1923 for the law to offer authors only a fifty-six-year term.
I don't think so, but it's possible.
If it was a mistake, then the consequence was that we got fewer authors to create in 1923 than we otherwise would have.
But we can't correct that mistake today by increasing the term.
No matter what we do today, we will not increase the number of authors who wrote in 1923\. Of course, we can increase the reward that those who write now get (or alternatively, increase the copyright burden that smothers many works that are today invisible). But increasing their reward will not increase their creativity in 1923\. What's not done is not done, and there's nothing we can do about that now.

These changes together should produce an _average_ copyright term that is much shorter than the current term.
Until 1976, the average term was just 32.2 years.
We should be aiming for the same.

No doubt the extremists will call these ideas “radical.”
(After all, I call them “extremists.”)
But again, the term I recommended was longer than the term under Richard Nixon.
How “radical” can it be to ask for a more generous copyright law than Richard Nixon presided over?

****3. Free Use Vs. Fair Use****

As I observed at the beginning of this book, property law originally granted property owners the right to control their property from the ground to the heavens.
The airplane came along.
The scope of property rights quickly changed.
There was no fuss, no constitutional challenge.
It made no sense anymore to grant that much control, given the emergence of that new technology.

Our Constitution gives Congress the power to give authors “exclusive right” to “their writings.”
Congress has given authors an exclusive right to “their writings” plus any derivative writings (made by others) that are sufficiently close to the author's original work.
Thus, if I write a book, and you base a movie on that book, I have the power to deny you the right to release that movie, even though that movie is not “my writing.”

Congress granted the beginnings of this right in 1870, when it expanded the exclusive right of copyright to include a right to control translations and dramatizations of a work.[^216]
The courts have expanded it slowly through judicial interpretation ever since.
This expansion has been commented upon by one of the law's greatest judges, Judge Benjamin Kaplan.

> So inured have we become to the extension of the monopoly to a large range of so-called derivative works, that we no longer sense the oddity of accepting such an enlargement of copyright while yet intoning the abracadabra of idea and expression.[^217]

I think it's time to recognize that there are airplanes in this field and the expansiveness of these rights of derivative use no longer make sense.
More precisely, they don't make sense for the period of time that a copyright runs.
And they don't make sense as an amorphous grant.
Consider each limitation in turn.

_Term:_ If Congress wants to grant a derivative right, then that right should be for a much shorter term.
It makes sense to protect John Grisham's right to sell the movie rights to his latest novel (or at least I'm willing to assume it does); but it does not make sense for that right to run for the same term as the underlying copyright.
The derivative right could be important in inducing creativity; it is not important long after the creative work is done.

_Scope:_ Likewise should the scope of derivative rights be narrowed.
Again, there are some cases in which derivative rights are important.
Those should be specified.
But the law should draw clear lines around regulated and unregulated uses of copyrighted material.
When all “reuse” of creative material was within the control of businesses, perhaps it made sense to require lawyers to negotiate the lines.
It no longer makes sense for lawyers to negotiate the lines.
Think about all the creative possibilities that digital technologies enable; now imagine pouring molasses into the machines.
That's what this general requirement of permission does to the creative process.
Smothers it.

This was the point that Alben made when describing the making of the Clint Eastwood CD. While it makes sense to require negotiation for foreseeable derivative rights—turning a book into a movie, or a poem into a musical score—it doesn't make sense to require negotiation for the unforeseeable.
Here, a statutory right would make much more sense.

In each of these cases, the law should mark the uses that are protected, and the presumption should be that other uses are not protected.
This is the reverse of the recommendation of my colleague Paul Goldstein.[^218]
His view is that the law should be written so that expanded protections follow expanded uses.

Goldstein's analysis would make perfect sense if the cost of the legal system were small.
But as we are currently seeing in the context of the Internet, the uncertainty about the scope of protection, and the incentives to protect existing architectures of revenue, combined with a strong copyright, weaken the process of innovation.

The law could remedy this problem either by removing protection beyond the part explicitly drawn or by granting reuse rights upon certain statutory conditions.
Either way, the effect would be to free a great deal of culture to others to cultivate.
And under a statutory rights regime, that reuse would earn artists more income.

### 4\. Liberate the Music—Again

The battle that got this whole war going was about music, so it wouldn't be fair to end this book without addressing the issue that is, to most people, most pressing—music.
There is no other policy issue that better teaches the lessons of this book than the battles around the sharing of music.

The appeal of file-sharing music was the crack cocaine of the Internet's growth.
It drove demand for access to the Internet more powerfully than any other single application.
It was the Internet's killer app—possibly in two senses of that word.
It no doubt was the application that drove demand for bandwidth.
It may well be the application that drives demand for regulations that in the end kill innovation on the network.

The aim of copyright, with respect to content in general and music in particular, is to create the incentives for music to be composed, performed, and, most importantly, spread.
The law does this by giving an exclusive right to a composer to control public performances of his work, and to a performing artist to control copies of her performance.

File-sharing networks complicate this model by enabling the spread of content for which the performer has not been paid.
But of course, that's not all the file-sharing networks do. As I described in chapter 5, they enable four different kinds of sharing:

A. There are some who are using sharing networks as substitutes for purchasing CDs.

B. There are also some who are using sharing networks to sample, on the way to purchasing CDs.

C. There are many who are using file-sharing networks to get access to content that is no longer sold but is still under copyright or that would have been too cumbersome to buy off the Net.

D. There are many who are using file-sharing networks to get access to content that is not copyrighted or to get access that the copyright owner plainly endorses.

Any reform of the law needs to keep these different uses in focus.
It must avoid burdening type D even if it aims to eliminate type A. The eagerness with which the law aims to eliminate type A, moreover, should depend upon the magnitude of type B. As with VCRs, if the net effect of sharing is actually not very harmful, the need for regulation is significantly weakened.

As I said in chapter 5, the actual harm caused by sharing is controversial.
For the purposes of this chapter, however, I assume the harm is real.
I assume, in other words, that type A sharing is significantly greater than type B, and is the dominant use of sharing networks.

Nonetheless, there is a crucial fact about the current technological context that we must keep in mind if we are to understand how the law should respond.

Today, file sharing is addictive.
In ten years, it won't be. It is addictive today because it is the easiest way to gain access to a broad range of content.
It won't be the easiest way to get access to a broad range of content in ten years.
Today, access to the Internet is cumbersome and slow—we in the United States are lucky to have broadband service at 1.5 MBs, and very rarely do we get service at that speed both up and down.
Although wireless access is growing, most of us still get access across wires.
Most only gain access through a machine with a keyboard.
The idea of the always on, always connected Internet is mainly just an idea.

But it will become a reality, and that means the way we get access to the Internet today is a technology in transition.
Policy makers should not make policy on the basis of technology in transition.
They should make policy on the basis of where the technology is going.
The question should not be, how should the law regulate sharing in this world?
The question should be, what law will we require when the network becomes the network it is clearly becoming?
That network is one in which every machine with electricity is essentially on the Net; where everywhere you are—except maybe the desert or the Rockies—you can instantaneously be connected to the Internet.
Imagine the Internet as ubiquitous as the best cell-phone service, where with the flip of a device, you are connected.

In that world, it will be extremely easy to connect to services that give you access to content on the fly—such as Internet radio, content that is streamed to the user when the user demands.
Here, then, is the critical point: When it is _extremely_ easy to connect to services that give access to content, it will be _easier_ to connect to services that give you access to content than it will be to download and store content _on the many devices you will have for playing content_.
It will be easier, in other words, to subscribe than it will be to be a database manager, as everyone in the download-sharing world of Napster-like technologies essentially is. Content services will compete with content sharing, even if the services charge money for the content they give access to. Already cell-phone services in Japan offer music (for a fee) streamed over cell phones (enhanced with plugs for headphones). The Japanese are paying for this content even though “free” content is available in the form of MP3s across the Web.[^219]

This point about the future is meant to suggest a perspective on the present: It is emphatically temporary.
The “problem” with file sharing—to the extent there is a real problem—is a problem that will increasingly disappear as it becomes easier to connect to the Internet.
And thus it is an extraordinary mistake for policy makers today to be “solving” this problem in light of a technology that will be gone tomorrow.
The question should not be how to regulate the Internet to eliminate file sharing (the Net will evolve that problem away). The question instead should be how to assure that artists get paid, during this transition between twentieth-century models for doing business and twenty-first-century technologies.

The answer begins with recognizing that there are different “problems” here to solve.
Let's start with type D content—uncopyrighted content or copyrighted content that the artist wants shared.
The “problem” with this content is to make sure that the technology that would enable this kind of sharing is not rendered illegal.
You can think of it this way: Pay phones are used to deliver ransom demands, no doubt.
But there are many who need to use pay phones who have nothing to do with ransoms.
It would be wrong to ban pay phones in order to eliminate kidnapping.

Type C content raises a different “problem.”
This is content that was, at one time, published and is no longer available.
It may be unavailable because the artist is no longer valuable enough for the record label he signed with to carry his work.
Or it may be unavailable because the work is forgotten.
Either way, the aim of the law should be to facilitate the access to this content, ideally in a way that returns something to the artist.

Again, the model here is the used book store.
Once a book goes out of print, it may still be available in libraries and used book stores.
But libraries and used book stores don't pay the copyright owner when someone reads or buys an out-of-print book.
That makes total sense, of course, since any other system would be so burdensome as to eliminate the possibility of used book stores' existing.
But from the author's perspective, this “sharing” of his content without his being compensated is less than ideal.

The model of used book stores suggests that the law could simply deem out-of-print music fair game.
If the publisher does not make copies of the music available for sale, then commercial and noncommercial providers would be free, under this rule, to “share” that content, even though the sharing involved making a copy.
The copy here would be incidental to the trade; in a context where commercial publishing has ended, trading music should be as free as trading books.

Alternatively, the law could create a statutory license that would ensure that artists get something from the trade of their work.
For example, if the law set a low statutory rate for the commercial sharing of content that was not offered for sale by a commercial publisher, and if that rate were automatically transferred to a trust for the benefit of the artist, then businesses could develop around the idea of trading this content, and artists would benefit from this trade.

This system would also create an incentive for publishers to keep works available commercially.
Works that are available commercially would not be subject to this license.
Thus, publishers could protect the right to charge whatever they want for content if they kept the work commercially available.
But if they don't keep it available, and instead, the computer hard disks of fans around the world keep it alive, then any royalty owed for such copying should be much less than the amount owed a commercial publisher.

The hard case is content of types A and B, and again, this case is hard only because the extent of the problem will change over time, as the technologies for gaining access to content change.
The law's solution should be as flexible as the problem is, understanding that we are in the middle of a radical transformation in the technology for delivering and accessing content.

So here's a solution that will at first seem very strange to both sides in this war, but which upon reflection, I suggest, should make some sense.

Stripped of the rhetoric about the sanctity of property, the basic claim of the content industry is this: A new technology (the Internet) has harmed a set of rights that secure copyright.
If those rights are to be protected, then the content industry should be compensated for that harm.
Just as the technology of tobacco harmed the health of millions of Americans, or the technology of asbestos caused grave illness to thousands of miners, so, too, has the technology of digital networks harmed the interests of the content industry.

I love the Internet, and so I don't like likening it to tobacco or asbestos.
But the analogy is a fair one from the perspective of the law.
And it suggests a fair response: Rather than seeking to destroy the Internet, or the p2p technologies that are currently harming content providers on the Internet, we should find a relatively simple way to compensate those who are harmed.

The idea would be a modification of a proposal that has been floated by Harvard law professor William Fisher.[^220]
Fisher suggests a very clever way around the current impasse of the Internet.
Under his plan, all content capable of digital transmission would (1) be marked with a digital watermark (don't worry about how easy it is to evade these marks; as you'll see, there's no incentive to evade them). Once the content is marked, then entrepreneurs would develop (2) systems to monitor how many items of each content were distributed.
On the basis of those numbers, then (3) artists would be compensated.
The compensation would be paid for by (4) an appropriate tax.

Fisher's proposal is careful and comprehensive.
It raises a million questions, most of which he answers well in his upcoming book, _Promises to Keep_.
The modification that I would make is relatively simple: Fisher imagines his proposal replacing the existing copyright system.
I imagine it complementing the existing system.
The aim of the proposal would be to facilitate compensation to the extent that harm could be shown.
This compensation would be temporary, aimed at facilitating a transition between regimes.
And it would require renewal after a period of years.
If it continues to make sense to facilitate free exchange of content, supported through a taxation system, then it can be continued.
If this form of protection is no longer necessary, then the system could lapse into the old system of controlling access.

Fisher would balk at the idea of allowing the system to lapse.
His aim is not just to ensure that artists are paid, but also to ensure that the system supports the widest range of “semiotic democracy” possible.
But the aims of semiotic democracy would be satisfied if the other changes I described were accomplished—in particular, the limits on derivative uses.
A system that simply charges for access would not greatly burden semiotic democracy if there were few limitations on what one was allowed to do with the content itself.

No doubt it would be difficult to calculate the proper measure of “harm” to an industry.
But the difficulty of making that calculation would be outweighed by the benefit of facilitating innovation.
This background system to compensate would also not need to interfere with innovative proposals such as Apple's MusicStore.
As experts predicted when Apple launched the MusicStore, it could beat “free” by being easier than free is. This has proven correct: Apple has sold millions of songs at even the very high price of 99 cents a song.
(At 99 cents, the cost is the equivalent of a per-song CD price, though the labels have none of the costs of a CD to pay.)
Apple's move was countered by Real Networks, offering music at just 79 cents a song.
And no doubt there will be a great deal of competition to offer and sell music on-line.

This competition has already occurred against the background of “free” music from p2p systems.
As the sellers of cable television have known for thirty years, and the sellers of bottled water for much more than that, there is nothing impossible at all about “competing with free.”
Indeed, if anything, the competition spurs the competitors to offer new and better products.
This is precisely what the competitive market was to be about.
Thus in Singapore, though piracy is rampant, movie theaters are often luxurious—with “first class” seats, and meals served while you watch a movie—as they struggle and succeed in finding ways to compete with “free.”

This regime of competition, with a backstop to assure that artists don't lose, would facilitate a great deal of innovation in the delivery of content.
That competition would continue to shrink type A sharing.
It would inspire an extraordinary range of new innovators—ones who would have a right to the content, and would no longer fear the uncertain and barbarically severe punishments of the law.

In summary, then, my proposal is this:

The Internet is in transition.
We should not be regulating a technology in transition.
We should instead be regulating to minimize the harm to interests affected by this technological change, while enabling, and encouraging, the most efficient technology we can create.

We can minimize that harm while maximizing the benefit to innovation by

1. guaranteeing the right to engage in type D sharing;

2. permitting noncommercial type C sharing without liability, and commercial type C sharing at a low and fixed rate set by statute;

3. while in this transition, taxing and compensating for type A sharing, to the extent actual harm is demonstrated.

But what if “piracy” doesn't disappear?
What if there is a competitive market providing content at a low cost, but a significant number of consumers continue to “take” content for nothing?
Should the law do something then?

Yes, it should.
But, again, what it should do depends upon how the facts develop.
These changes may not eliminate type A sharing.
But the real issue is not whether it eliminates sharing in the abstract.
The real issue is its effect on the market.
Is it better (a) to have a technology that is 95 percent secure and produces a market of size _x_, or (b) to have a technology that is 50 percent secure but produces a market of five times _x_? Less secure might produce more unauthorized sharing, but it is likely to also produce a much bigger market in authorized sharing.
The most important thing is to assure artists' compensation without breaking the Internet.
Once that's assured, then it may well be appropriate to find ways to track down the petty pirates.

But we're a long way away from whittling the problem down to this subset of type A sharers.
And our focus until we're there should not be on finding ways to break the Internet.
Our focus until we're there should be on how to make sure the artists are paid, while protecting the space for innovation and creativity that the Internet is.

### 5\. Fire Lots of Lawyers

I'm a lawyer.
I make lawyers for a living.
I believe in the law.
I believe in the law of copyright.
Indeed, I have devoted my life to working in law, not because there are big bucks at the end but because there are ideals at the end that I would love to live.

Yet much of this book has been a criticism of lawyers, or the role lawyers have played in this debate.
The law speaks to ideals, but it is my view that our profession has become too attuned to the client.
And in a world where the rich clients have one strong view, the unwillingness of the profession to question or counter that one strong view queers the law.

The evidence of this bending is compelling.
I'm attacked as a “radical” by many within the profession, yet the positions that I am advocating are precisely the positions of some of the most moderate and significant figures in the history of this branch of the law.
Many, for example, thought crazy the challenge that we brought to the Copyright Term Extension Act.
Yet just thirty years ago, the dominant scholar and practitioner in the field of copyright, Melville Nimmer, thought it obvious.[^221]

However, my criticism of the role that lawyers have played in this debate is not just about a professional bias.
It is more importantly about our failure to actually reckon the costs of the law.

Economists are supposed to be good at reckoning costs and benefits.
But more often than not, economists, with no clue about how the legal system actually functions, simply assume that the transaction costs of the legal system are slight.[^222]
They see a system that has been around for hundreds of years, and they assume it works the way their elementary school civics class taught them it works.

But the legal system doesn't work.
Or more accurately, it doesn't work for anyone except those with the most resources.
Not because the system is corrupt.
I don't think our legal system (at the federal level, at least) is at all corrupt.
I mean simply because the costs of our legal system are so astonishingly high that justice can practically never be done.

These costs distort free culture in many ways.
A lawyer's time is billed at the largest firms at more than $400 per hour.
How much time should such a lawyer spend reading cases carefully, or researching obscure strands of authority?
The answer is the increasing reality: very little.
The law depended upon the careful articulation and development of doctrine, but the careful articulation and development of legal doctrine depends upon careful work.
Yet that careful work costs too much, except in the most high-profile and costly cases.

The costliness and clumsiness and randomness of this system mock our tradition.
And lawyers, as well as academics, should consider it their duty to change the way the law works—or better, to change the law so that it works.
It is wrong that the system works well only for the top 1 percent of the clients.
It could be made radically more efficient, and inexpensive, and hence radically more just.

But until that reform is complete, we as a society should keep the law away from areas that we know it will only harm.
And that is precisely what the law will too often do if too much of our culture is left to its review.

Think about the amazing things your kid could do or make with digital technology—the film, the music, the Web page, the blog.
Or think about the amazing things your community could facilitate with digital technology—a wiki, a barn raising, activism to change something.
Think about all those creative things, and then imagine cold molasses poured onto the machines.
This is what any regime that requires permission produces.
Again, this is the reality of Brezhnev's Russia.

The law should regulate in certain areas of culture—but it should regulate culture only where that regulation does good.
Yet lawyers rarely test their power, or the power they promote, against this simple pragmatic question: “Will it do good?” When challenged about the expanding reach of the law, the lawyer answers, “Why not?”

We should ask, “Why?” Show me why your regulation of culture is needed.
Show me how it does good.
And until you can show me both, keep your lawyers away.


[^210]: See, for example, Marc Rotenberg, “Fair Information Practices and the Architecture of Privacy (What Larry Doesn't Get),” *Stanford Technology Law Review* 1 (2001): par. 6-18, available at link #72 (describing examples in which technology defines privacy policy). See also Jeffrey Rosen, *The Naked Crowd: Reclaiming Security and Freedom in an Anxious Age* (New York: Random House, 2004) (mapping tradeoffs between technology and privacy).

[^211]: *Willful Infringement: A Report from the Front Lines of the Real Culture Wars* (2003), produced by Jed Horovitz, directed by Greg Hittelman, a Fiat Lucre production, available at link #72.

[^212]: The proposal I am advancing here would apply to American works only.
	Obviously, I believe it would be beneficial for the same idea to be adopted by other countries as well.

[^213]: There would be a complication with derivative works that I have not solved here.
	In my view, the law of derivatives creates a more complicated system than is justified by the marginal incentive it creates.

[^214]: “A Radical Rethink,” *Economist*, 366:8308 (25 January 2003): 15, available at link #74.

[^215]: Department of Veterans Affairs, Veteran's Application for Compensation and/or Pension, VA Form 21-526 (OMB Approved No. 2900-0001), available at link #75.

[^216]: Benjamin Kaplan, *An Unhurried View of Copyright* (New York: Columbia University Press, 1967), 32.

[^217]: Ibid., 56.

[^218]: Paul Goldstein, *Copyright's Highway: From Gutenberg to the Celestial Jukebox* (Stanford: Stanford University Press, 2003), 187-216.

[^219]: See, for example, “Music Media Watch,” The J@pan Inc. Newsletter, 3 April 2002, available at link #76.

[^220]: William Fisher, *Digital Music: Problems and Possibilities* (last revised: 10 October 2000), available at link #77; William Fisher, *Promises to Keep: Technology, Law, and the Future of Entertainment* (forthcoming) (Stanford: Stanford University Press, 2004), ch. 6, available at link #78.
	Professor Netanel has proposed a related idea that would exempt noncommercial sharing from the reach of copyright and would establish compensation to artists to balance any loss.
	See Neil Weinstock Netanel, “Impose a Noncommercial Use Levy to Allow Free P2P File Sharing,” available at link #79.  For other proposals, see Lawrence Lessig, “Who's Holding Back Broadband?” *Washington Post*, 8 January 2002, A17; Philip S. Corwin on behalf of Sharman Networks, A Letter to Senator Joseph R. Biden, Jr., Chairman of the Senate Foreign Relations Committee, 26 February 2002, available at link #80; Serguei Osokine, *A Quick Case for Intellectual Property Use Fee (IPUF)*, 3 March 2002, available at link #81; Jefferson Graham, “Kazaa, Verizon Propose to Pay Artists Directly,” *USA Today*, 13 May 2002, available at link #82; Steven M. Cherry, “Getting Copyright Right,” IEEE Spectrum Online, 1 July 2002, available at link #83; Declan McCullagh, “Verizon's Copyright Campaign,” CNET News.com, 27 August 2002, available at link #84.

    Fisher's proposal is very similar to Richard Stallman's proposal for DAT.
	Unlike Fisher's, Stallman's proposal would not pay artists directly proportionally, though more popular artists would get more than the less popular.
	As is typical with Stallman, his proposal predates the current debate by about a decade.
	See link #85.

[^221]: Lawrence Lessig, “Copyright's First Amendment” (Melville B. Nimmer Memorial Lecture), *UCLA Law Review* 48 (2001): 1057, 1069-70.

[^222]: A good example is the work of Professor Stan Liebowitz.
	Liebowitz is to be commended for his careful review of data about infringement, leading him to question his own publicly stated position—twice.
	He initially predicted that downloading would substantially harm the industry.
	He then revised his view in light of the data, and he has since revised his view again.
	Compare Stan J. Liebowitz, *Rethinking the Network Economy: The True Forces That Drive the Digital Marketplace* (New York: Amacom, 2002), 173 (reviewing his original view but expressing skepticism) with Stan J. Liebowitz, “Will MP3s Annihilate the Record Industry?” working paper, June 2003, available at link #86.

    Liebowitz's careful analysis is extremely valuable in estimating the effect of file-sharing technology.
	In my view, however, he underestimates the costs of the legal system.
	See, for example, *Rethinking*, 174-76.
